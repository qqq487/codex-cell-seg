ChannelGate input x size =  torch.Size([2, 64, 300, 200])
SpatialGate input x size =  torch.Size([2, 64, 300, 200])
SpatialGate after compress x shape =  torch.Size([2, 2, 300, 200])
SpatialGate x out shape =  torch.Size([2, 1, 300, 200])
SpatialGate scale shape =  torch.Size([2, 1, 300, 200])
SpatialGate output x size =  torch.Size([2, 64, 300, 200])
ChannelGate input x size =  torch.Size([1, 64, 300, 200])
SpatialGate input x size =  torch.Size([1, 64, 300, 200])
SpatialGate after compress x shape =  torch.Size([1, 2, 300, 200])
SpatialGate x out shape =  torch.Size([1, 1, 300, 200])
SpatialGate scale shape =  torch.Size([1, 1, 300, 200])
SpatialGate output x size =  torch.Size([1, 64, 300, 200])
INFO: Starting training:
        Epochs:          1000
        Batch size:      2
        Learning rate:   1e-06
        Training size:   3
        Validation size: 0
        Checkpoints:     True
        Device:          cuda
        Images scaling:  1
        Mixed Precision: True
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.34it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.09it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.50it/s]
Epoch 1/1000: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.62img/s, loss (batch)=2.65]
INFO: Checkpoint 1 saved!
Epoch 2/1000:   0%|                                                                                                                                                                  | 0/3 [00:00<?, ?img/s]
  0%|                                                                                                                                                                                 | 0/1 [00:00<?, ?it/s]
ChannelGate input x size =  torch.Size([2, 64, 300, 200])
SpatialGate input x size =  torch.Size([2, 64, 300, 200])
SpatialGate after compress x shape =  torch.Size([2, 2, 300, 200])
SpatialGate x out shape =  torch.Size([2, 1, 300, 200])
SpatialGate scale shape =  torch.Size([2, 1, 300, 200])
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.92it/s]
Epoch 2/1000:  67%|██████████████████████████████████████████████████████████████████████████████████████████                                             | 2/3 [00:01<00:00,  1.78img/s, loss (batch)=2.68]
Traceback (most recent call last):                                                                                                                                                    | 0/1 [00:00<?, ?it/s]
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/numba/core/serialize.py", line 29, in _numba_unpickle
    def _numba_unpickle(address, bytedata, hashed):
KeyboardInterrupt
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "train-multi.py", line 211, in <module>
    amp=args.amp)
  File "train-multi.py", line 86, in train_net
    for batch in train_loader:
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/utils/data/dataset.py", line 311, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/tmp2/chacotw/unet/Pytorch-UNet/utils/data_loading.py", line 292, in __getitem__
    img, mask = self.cell_transform(img, mask, 1)
  File "/tmp2/chacotw/unet/Pytorch-UNet/utils/data_loading.py", line 238, in cell_transform
    flow = cellpose.dynamics.labels_to_flows([labeled_array])
  File "/tmp2/chacotw/unet/Pytorch-UNet/cellpose/dynamics.py", line 327, in labels_to_flows
    veci = [masks_to_flows(labels[n][0],use_gpu=use_gpu, device=device) for n in trange(nimg)]
  File "/tmp2/chacotw/unet/Pytorch-UNet/cellpose/dynamics.py", line 327, in <listcomp>
    veci = [masks_to_flows(labels[n][0],use_gpu=use_gpu, device=device) for n in trange(nimg)]
  File "/tmp2/chacotw/unet/Pytorch-UNet/cellpose/dynamics.py", line 287, in masks_to_flows
    mu, mu_c = masks_to_flows_device(masks, device=device)
  File "/tmp2/chacotw/unet/Pytorch-UNet/cellpose/dynamics.py", line 222, in masks_to_flows_cpu
    T = _extend_centers(T, y, x, ymed, xmed, np.int32(lx), np.int32(niter))
SystemError: CPUDispatcher(<function _extend_centers at 0x7f7ce4b1fa70>) returned a result with an error set