INFO: Starting training:
        Epochs:          15000
        Batch size:      2
        Learning rate:   1e-06
        Training size:   3
        Validation size: 0
        Checkpoints:     True
        Device:          cuda
        Images scaling:  1
        Mixed Precision: True
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.81it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.11it/s]
Epoch 1/15000:   0%|                                                                                                                                                                 | 0/3 [00:00<?, ?img/s]
Traceback (most recent call last):
  File "train-multi.py", line 211, in <module>
    amp=args.amp)
  File "train-multi.py", line 99, in train_net
    masks_pred = net(images)
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/tmp2/chacotw/unet/Pytorch-UNet/unet/unet_model.py", line 38, in forward
    x1 = self.sa0(self.ca0(self.inc(x)))
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/tmp2/chacotw/unet/Pytorch-UNet/unet/cbam.py", line 112, in forward
    channel_out = self.spatial(x[batch_i][channel_i])
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/tmp2/chacotw/unet/Pytorch-UNet/unet/cbam.py", line 15, in forward
    x = self.conv(x)
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 440, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected 4-dimensional input for 4-dimensional weight [1, 1, 7, 7], but got 2-dimensional input of size [300, 200] instead
SpatialGate input x size =  torch.Size([2, 64, 300, 200])