INFO: Starting training:
        Epochs:          15000
        Batch size:      2
        Learning rate:   1e-06
        Training size:   3
        Validation size: 0
        Checkpoints:     True
        Device:          cuda
        Images scaling:  1
        Mixed Precision: True
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s]
Epoch 1/15000:   0%|                                                                                                                                                                 | 0/3 [00:00<?, ?img/s]
Traceback (most recent call last):
  File "train-multi.py", line 211, in <module>
    amp=args.amp)
  File "train-multi.py", line 110, in train_net
    grad_scaler.scale(loss).backward()
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/master/09/chacotw/miniconda3/envs/unet/lib/python3.7/site-packages/torch/autograd/__init__.py", line 149, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.HalfTensor [300, 200]], which is output 0 of SelectBackward, is at version 128; expected version 127 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
SpatialGate input x size =  torch.Size([2, 64, 300, 200])